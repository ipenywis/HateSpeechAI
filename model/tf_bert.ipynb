{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.4.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.7 MB 1.6 MB/s eta 0:00:01    |████████████████████████▋       | 9.0 MB 1.8 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting sklearn\n",
      "  Using cached sklearn-0.0.tar.gz (1.1 kB)\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.3 MB 1.3 MB/s eta 0:00:01    |████████▍                       | 3.0 MB 1.8 MB/s eta 0:00:05\n",
      "\u001b[?25hCollecting numpy\n",
      "  Downloading numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 16.8 MB 79 kB/s  eta 0:00:01     |██████████████████████████████▏ | 15.9 MB 2.3 MB/s eta 0:00:01     |██████████████████████████████▍ | 16.0 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-hub\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting tf-models-official\n",
      "  Downloading tf_models_official-2.9.0-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 573 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorflow-text\n",
      "  Downloading tensorflow_text-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.6 MB 1.8 MB/s eta 0:00:01     |███████████▋                    | 1.7 MB 101 kB/s eta 0:00:30     |██████████████████              | 2.6 MB 832 kB/s eta 0:00:03\n",
      "\u001b[?25hCollecting tensorflow\n",
      "  Downloading tensorflow-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 511.7 MB 84 bytes/s a 0:00:01   |▏                               | 1.9 MB 368 kB/s eta 0:23:03     |▎                               | 5.3 MB 342 kB/s eta 0:24:37     |████▉                           | 77.7 MB 2.0 MB/s eta 0:03:41     |█████▉                          | 94.0 MB 1.3 MB/s eta 0:05:11     |██████                          | 95.3 MB 1.3 MB/s eta 0:05:10     |███████▌                        | 119.8 MB 2.3 MB/s eta 0:02:53     |█████████                       | 143.7 MB 2.0 MB/s eta 0:03:08     |██████████                      | 159.9 MB 2.7 MB/s eta 0:02:10     |██████████▋                     | 169.7 MB 1.3 MB/s eta 0:04:22     |███████████▏                    | 179.3 MB 2.0 MB/s eta 0:02:49     |███████████▋                    | 185.3 MB 985 kB/s eta 0:05:32     |███████████▊                    | 186.8 MB 2.0 MB/s eta 0:02:41     |████████████▍                   | 197.3 MB 626 kB/s eta 0:08:22     |████████████▍                   | 197.7 MB 626 kB/s eta 0:08:22     |█████████████▍                  | 213.4 MB 124 kB/s eta 0:40:02     |█████████████▋                  | 218.5 MB 1.4 MB/s eta 0:03:32     |█████████████▋                  | 218.5 MB 1.4 MB/s eta 0:03:32     |███████████████▌                | 248.3 MB 1.2 MB/s eta 0:03:45     |████████████████▏               | 259.2 MB 2.0 MB/s eta 0:02:09     |█████████████████               | 270.8 MB 1.6 MB/s eta 0:02:30     |██████████████████▎             | 292.7 MB 1.4 MB/s eta 0:02:33     |███████████████████▏            | 306.1 MB 2.3 MB/s eta 0:01:31     |████████████████████▌           | 328.2 MB 1.1 MB/s eta 0:02:45     |████████████████████▊           | 332.0 MB 1.8 MB/s eta 0:01:40     |█████████████████████▌          | 342.9 MB 1.6 MB/s eta 0:01:49     |██████████████████████▋         | 361.9 MB 971 kB/s eta 0:02:35     |███████████████████████         | 366.7 MB 1.0 MB/s eta 0:02:23     |████████████████████████▏       | 385.6 MB 911 kB/s eta 0:02:19     |████████████████████████▍       | 390.2 MB 516 kB/s eta 0:03:56     |████████████████████████▋       | 394.2 MB 187 kB/s eta 0:10:28     |████████████████████████▉       | 397.9 MB 445 kB/s eta 0:04:16     |█████████████████████████       | 400.6 MB 658 kB/s eta 0:02:49     |██████████████████████████      | 416.7 MB 2.3 MB/s eta 0:00:42     |███████████████████████████     | 431.9 MB 1.0 MB/s eta 0:01:19     |███████████████████████████     | 432.2 MB 1.0 MB/s eta 0:01:18     |████████████████████████████    | 448.4 MB 708 kB/s eta 0:01:30     |█████████████████████████████▍  | 469.2 MB 1.3 MB/s eta 0:00:34     |██████████████████████████████▎ | 483.6 MB 782 kB/s eta 0:00:36     |███████████████████████████████▏| 497.7 MB 389 kB/s eta 0:00:36     |███████████████████████████████▍| 502.0 MB 306 kB/s eta 0:00:32\n",
      "\u001b[?25hCollecting pytz>=2020.1\n",
      "  Using cached pytz-2022.1-py2.py3-none-any.whl (503 kB)\n",
      "Collecting python-dateutil>=2.8.1\n",
      "  Using cached python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 31.0 MB 93 kB/s  eta 0:00:01    |██████▌                         | 6.3 MB 328 kB/s eta 0:01:16     |██████████████████████▌         | 21.8 MB 1.7 MB/s eta 0:00:06\n",
      "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
      "  Downloading kiwisolver-1.4.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 624 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/lib/python3/dist-packages (from matplotlib) (7.0.0)\n",
      "Collecting packaging>=20.0\n",
      "  Using cached packaging-21.3-py3-none-any.whl (40 kB)\n",
      "Collecting fonttools>=4.22.0\n",
      "  Downloading fonttools-4.33.3-py3-none-any.whl (930 kB)\n",
      "\u001b[K     |████████████████████████████████| 930 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cycler>=0.10\n",
      "  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
      "Collecting pyparsing>=2.2.1\n",
      "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "\u001b[K     |████████████████████████████████| 98 kB 373 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/lib/python3/dist-packages (from tensorflow-hub) (3.11.4)\n",
      "Collecting gin-config\n",
      "  Using cached gin_config-0.5.0-py3-none-any.whl (61 kB)\n",
      "Processing /home/islempenywis/.cache/pip/wheels/29/da/11/144cc25aebdaeb4931b231e25fd34b394e6a5725cbb2f50106/kaggle-1.5.12-py3-none-any.whl\n",
      "Collecting sacrebleu\n",
      "  Using cached sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /usr/lib/python3/dist-packages (from tf-models-official) (5.3.1)\n",
      "Collecting google-api-python-client>=1.6.7\n",
      "  Downloading google_api_python_client-2.48.0-py2.py3-none-any.whl (8.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 8.5 MB 1.3 MB/s eta 0:00:01     |█▏                              | 296 kB 739 kB/s eta 0:00:12\n",
      "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
      "  Using cached tensorflow_model_optimization-0.7.2-py2.py3-none-any.whl (237 kB)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Using cached py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.16.1-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 1.5 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycocotools\n",
      "  Using cached pycocotools-2.0.4.tar.gz (106 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h    Preparing wheel metadata ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/lib/python3/dist-packages (from tf-models-official) (5.5.1)\n",
      "Collecting tf-slim>=1.1.0\n",
      "  Using cached tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "Requirement already satisfied: six in /usr/lib/python3/dist-packages (from tf-models-official) (1.14.0)\n",
      "Collecting tensorflow-datasets\n",
      "  Using cached tensorflow_datasets-4.5.2-py3-none-any.whl (4.2 MB)\n",
      "Collecting scipy>=0.19.1\n",
      "  Downloading scipy-1.8.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 41.6 MB 44 kB/s  eta 0:00:01    |█▎                              | 1.6 MB 907 kB/s eta 0:00:45     |███████▊                        | 10.0 MB 357 kB/s eta 0:01:29     |█████████████████▍              | 22.6 MB 1.9 MB/s eta 0:00:10     |██████████████████████████████▍ | 39.5 MB 1.6 MB/s eta 0:00:02\n",
      "\u001b[?25hCollecting Cython\n",
      "  Using cached Cython-0.29.30-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)\n",
      "Collecting seqeval\n",
      "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
      "Collecting oauth2client\n",
      "  Using cached oauth2client-4.1.3-py2.py3-none-any.whl (98 kB)\n",
      "Collecting opencv-python-headless\n",
      "  Using cached opencv_python_headless-4.5.5.64-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (47.8 MB)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.96-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.2 MB 52 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting h5py>=2.9.0\n",
      "  Downloading h5py-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.5 MB 736 kB/s eta 0:00:01     |███████████████████████████▍    | 3.8 MB 592 kB/s eta 0:00:02\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 888 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.5 MB 158 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Using cached termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.46.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 447 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0\n",
      "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 924 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[K     |████████████████████████████████| 81 kB 221 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tensorboard<2.10,>=2.9\n",
      "  Downloading tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.8 MB 2.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting flatbuffers<2,>=1.12\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 962 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow) (45.2.0)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Collecting joblib>=1.0.0\n",
      "  Using cached joblib-1.1.0-py2.py3-none-any.whl (306 kB)\n",
      "Requirement already satisfied: certifi in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (2019.11.28)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (2.22.0)\n",
      "Collecting python-slugify\n",
      "  Using cached python_slugify-6.1.2-py2.py3-none-any.whl (9.4 kB)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle>=1.3.9->tf-models-official) (1.25.8)\n",
      "Collecting tqdm\n",
      "  Using cached tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
      "Requirement already satisfied: colorama in /usr/lib/python3/dist-packages (from sacrebleu->tf-models-official) (0.4.3)\n",
      "Collecting portalocker\n",
      "  Using cached portalocker-2.4.0-py2.py3-none-any.whl (16 kB)\n",
      "Collecting regex\n",
      "  Downloading regex-2022.4.24-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (764 kB)\n",
      "\u001b[K     |████████████████████████████████| 764 kB 1.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate>=0.8.9\n",
      "  Using cached tabulate-0.8.9-py3-none-any.whl (25 kB)\n",
      "Collecting httplib2<1dev,>=0.15.0\n",
      "  Using cached httplib2-0.20.4-py3-none-any.whl (96 kB)\n",
      "Collecting google-auth-httplib2>=0.1.0\n",
      "  Using cached google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5\n",
      "  Downloading google_api_core-2.8.0-py3-none-any.whl (114 kB)\n",
      "\u001b[K     |████████████████████████████████| 114 kB 681 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting uritemplate<5,>=3.0.1\n",
      "  Using cached uritemplate-4.1.1-py2.py3-none-any.whl (10 kB)\n",
      "Collecting google-auth<3.0.0dev,>=1.16.0\n",
      "  Downloading google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "\u001b[K     |████████████████████████████████| 156 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting dm-tree~=0.1.1\n",
      "  Downloading dm_tree-0.1.7-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (142 kB)\n",
      "\u001b[K     |████████████████████████████████| 142 kB 1.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typeguard>=2.7\n",
      "  Using cached typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
      "Collecting tensorflow-metadata\n",
      "  Downloading tensorflow_metadata-1.8.0-py3-none-any.whl (50 kB)\n",
      "\u001b[K     |████████████████████████████████| 50 kB 81 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-resources; python_version < \"3.9\"\n",
      "  Downloading importlib_resources-5.7.1-py3-none-any.whl (28 kB)\n",
      "Collecting dill\n",
      "  Using cached dill-0.3.4-py2.py3-none-any.whl (86 kB)\n",
      "Collecting promise\n",
      "  Using cached promise-2.3.tar.gz (19 kB)\n",
      "Collecting rsa>=3.1.4\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1>=0.1.7\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Collecting pyasn1-modules>=0.0.5\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow) (0.34.2)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 916 kB/s eta 0:00:01     |██████▊                         | 20 kB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Downloading Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "\u001b[K     |████████████████████████████████| 224 kB 1.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting text-unidecode>=1.3\n",
      "  Using cached text_unidecode-1.3-py2.py3-none-any.whl (78 kB)\n",
      "Collecting googleapis-common-protos<2.0dev,>=1.52.0\n",
      "  Downloading googleapis_common_protos-1.56.1-py2.py3-none-any.whl (211 kB)\n",
      "\u001b[K     |████████████████████████████████| 211 kB 870 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.1.0-py3-none-any.whl (9.2 kB)\n",
      "Collecting zipp>=3.1.0; python_version < \"3.10\"\n",
      "  Using cached zipp-3.8.0-py3-none-any.whl (5.4 kB)\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow) (3.1.0)\n",
      "Building wheels for collected packages: sklearn, py-cpuinfo, pycocotools, seqeval, termcolor, promise\n",
      "  Building wheel for sklearn (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sklearn: filename=sklearn-0.0-py2.py3-none-any.whl size=1315 sha256=359bf96c63999dd7918f696bd4baa026cec9d48333c47fe6c8946d6aa7be4e4d\n",
      "  Stored in directory: /home/islempenywis/.cache/pip/wheels/22/0b/40/fd3f795caaa1fb4c6cb738bc1f56100be1e57da95849bfc897\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22245 sha256=d6b527996d4a71e980750e5e8d09db29f4ea55d2b8c886abc0932f0e2f9fc7c6\n",
      "  Stored in directory: /home/islempenywis/.cache/pip/wheels/57/cb/6d/bab2257f26c5be4a96ff65c3d2a7122c96529b73773ee37f36\n",
      "  Building wheel for pycocotools (PEP 517) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.4-cp38-cp38-linux_x86_64.whl size=418825 sha256=873afc3866824509ea4c90a7ed37dce9e10f6a5e3f24f3624a5f89c366361f83\n",
      "  Stored in directory: /home/islempenywis/.cache/pip/wheels/dd/e2/43/3e93cd653b3346b3d702bb0509bc611189f95d60407bff1484\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16170 sha256=40ed2318881ff44fb7ab6e93106483d62049edf7103b31362f0bd0ceed288ea6\n",
      "  Stored in directory: /home/islempenywis/.cache/pip/wheels/ad/5c/ba/05fa33fa5855777b7d686e843ec07452f22a66a138e290e732\n",
      "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4830 sha256=be648652a88577c51343ee173e61089ce19030bc2d6a1d6a9d6a2b15a27e291f\n",
      "  Stored in directory: /home/islempenywis/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21493 sha256=4668e121ad36edad6e269b581daf952f17b894a6a2a62e8b0a092204710d1c3f\n",
      "  Stored in directory: /home/islempenywis/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
      "Successfully built sklearn py-cpuinfo pycocotools seqeval termcolor promise\n",
      "\u001b[31mERROR: launchpadlib 1.10.13 requires testresources, which is not installed.\u001b[0m\n",
      "\u001b[31mERROR: googleapis-common-protos 1.56.1 has requirement protobuf>=3.15.0, but you'll have protobuf 3.11.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: google-api-core 2.8.0 has requirement protobuf>=3.12.0, but you'll have protobuf 3.11.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-metadata 1.8.0 has requirement protobuf<4,>=3.13, but you'll have protobuf 3.11.4 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: tensorflow-datasets 4.5.2 has requirement protobuf>=3.12.2, but you'll have protobuf 3.11.4 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pytz, numpy, python-dateutil, pandas, scipy, threadpoolctl, joblib, scikit-learn, sklearn, kiwisolver, pyparsing, packaging, fonttools, cycler, matplotlib, tensorflow-hub, gin-config, text-unidecode, python-slugify, tqdm, kaggle, portalocker, regex, tabulate, sacrebleu, httplib2, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, google-auth-httplib2, googleapis-common-protos, google-api-core, uritemplate, google-api-python-client, dm-tree, tensorflow-model-optimization, py-cpuinfo, typeguard, tensorflow-addons, h5py, gast, tensorflow-io-gcs-filesystem, libclang, termcolor, astunparse, absl-py, typing-extensions, grpcio, keras, google-pasta, wrapt, tensorboard-data-server, tensorboard-plugin-wit, zipp, importlib-metadata, markdown, requests-oauthlib, google-auth-oauthlib, werkzeug, tensorboard, flatbuffers, tensorflow-estimator, keras-preprocessing, opt-einsum, tensorflow, tensorflow-text, pycocotools, tf-slim, tensorflow-metadata, importlib-resources, dill, promise, tensorflow-datasets, Cython, seqeval, oauth2client, opencv-python-headless, sentencepiece, tf-models-official\n",
      "Successfully installed Cython-0.29.30 absl-py-1.0.0 astunparse-1.6.3 cachetools-5.1.0 cycler-0.11.0 dill-0.3.4 dm-tree-0.1.7 flatbuffers-1.12 fonttools-4.33.3 gast-0.4.0 gin-config-0.5.0 google-api-core-2.8.0 google-api-python-client-2.48.0 google-auth-2.6.6 google-auth-httplib2-0.1.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.56.1 grpcio-1.46.1 h5py-3.6.0 httplib2-0.20.4 importlib-metadata-4.11.3 importlib-resources-5.7.1 joblib-1.1.0 kaggle-1.5.12 keras-2.9.0 keras-preprocessing-1.1.2 kiwisolver-1.4.2 libclang-14.0.1 markdown-3.3.7 matplotlib-3.5.2 numpy-1.22.3 oauth2client-4.1.3 opencv-python-headless-4.5.5.64 opt-einsum-3.3.0 packaging-21.3 pandas-1.4.2 portalocker-2.4.0 promise-2.3 py-cpuinfo-8.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycocotools-2.0.4 pyparsing-3.0.9 python-dateutil-2.8.2 python-slugify-6.1.2 pytz-2022.1 regex-2022.4.24 requests-oauthlib-1.3.1 rsa-4.8 sacrebleu-2.0.0 scikit-learn-1.1.0 scipy-1.8.1 sentencepiece-0.1.96 seqeval-1.2.2 sklearn-0.0 tabulate-0.8.9 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.0 tensorflow-addons-0.16.1 tensorflow-datasets-4.5.2 tensorflow-estimator-2.9.0 tensorflow-hub-0.12.0 tensorflow-io-gcs-filesystem-0.26.0 tensorflow-metadata-1.8.0 tensorflow-model-optimization-0.7.2 tensorflow-text-2.9.0 termcolor-1.1.0 text-unidecode-1.3 tf-models-official-2.9.0 tf-slim-1.1.0 threadpoolctl-3.1.0 tqdm-4.64.0 typeguard-2.13.3 typing-extensions-4.2.0 uritemplate-4.1.1 werkzeug-2.1.2 wrapt-1.14.1 zipp-3.8.0\n",
      "Collecting tensorflowjs\n",
      "  Using cached tensorflowjs-3.17.0-py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: six<2,>=1.12.0 in /usr/lib/python3/dist-packages (from tensorflowjs) (1.14.0)\n",
      "Collecting tensorflow-hub<0.13,>=0.7.0\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Collecting tensorflow<3,>=2.1.0\n",
      "  Using cached tensorflow-2.9.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
      "Collecting packaging~=20.9\n",
      "  Using cached packaging-20.9-py2.py3-none-any.whl (40 kB)\n",
      "Collecting numpy>=1.12.0\n",
      "  Using cached numpy-1.22.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /usr/lib/python3/dist-packages (from tensorflow-hub<0.13,>=0.7.0->tensorflowjs) (3.11.4)\n",
      "Collecting typing-extensions>=3.6.6\n",
      "  Using cached typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (45.2.0)\n",
      "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0\n",
      "  Using cached tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
      "Collecting flatbuffers<2,>=1.12\n",
      "  Using cached flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.26.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "Collecting keras<2.10.0,>=2.9.0rc0\n",
      "  Using cached keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Using cached grpcio-1.46.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Using cached h5py-3.6.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "Collecting tensorboard<2.10,>=2.9\n",
      "  Using cached tensorboard-2.9.0-py3-none-any.whl (5.8 MB)\n",
      "Collecting keras-preprocessing>=1.1.1\n",
      "  Using cached Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Processing /home/islempenywis/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501/termcolor-1.1.0-py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Using cached wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-14.0.1-py2.py3-none-manylinux1_x86_64.whl (14.5 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting pyparsing>=2.0.2\n",
      "  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/lib/python3/dist-packages (from astunparse>=1.6.0->tensorflow<3,>=2.1.0->tensorflowjs) (0.34.2)\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached Markdown-3.3.7-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Using cached tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Using cached tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
      "Collecting werkzeug>=1.0.1\n",
      "  Using cached Werkzeug-2.1.2-py3-none-any.whl (224 kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/lib/python3/dist-packages (from tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (2.22.0)\n",
      "Collecting importlib-metadata>=4.4; python_version < \"3.10\"\n",
      "  Using cached importlib_metadata-4.11.3-py3-none-any.whl (18 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.1.0-py3-none-any.whl (9.2 kB)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.0)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/lib/python3/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
      "Installing collected packages: numpy, tensorflow-hub, typing-extensions, gast, tensorflow-estimator, absl-py, flatbuffers, astunparse, tensorflow-io-gcs-filesystem, keras, grpcio, h5py, importlib-metadata, markdown, tensorboard-data-server, tensorboard-plugin-wit, cachetools, pyasn1, rsa, pyasn1-modules, google-auth, werkzeug, requests-oauthlib, google-auth-oauthlib, tensorboard, keras-preprocessing, termcolor, google-pasta, wrapt, pyparsing, packaging, libclang, opt-einsum, tensorflow, tensorflowjs\n",
      "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.1.0 flatbuffers-1.12 gast-0.4.0 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.46.1 h5py-3.6.0 importlib-metadata-4.11.3 keras-2.9.0 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.7 numpy-1.22.3 opt-einsum-3.3.0 packaging-21.3 pyasn1-0.4.8 pyasn1-modules-0.2.8 pyparsing-3.0.9 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.9.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.0 tensorflow-estimator-2.9.0 tensorflow-hub-0.12.0 tensorflow-io-gcs-filesystem-0.26.0 tensorflowjs-3.17.0 termcolor-1.1.0 typing-extensions-4.2.0 werkzeug-2.1.2 wrapt-1.14.1\n"
     ]
    }
   ],
   "source": [
    "#Install dependencies\n",
    "!pip install pandas sklearn matplotlib numpy tensorflow-hub tf-models-official tensorflow-text tensorflow\n",
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GITHUB REPO TOKEN\n",
    "# https://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@github.com/ipenywis/HateSpeechAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install jupyterthemes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !jt -t onedork -T -N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 uninstall -y tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Running on GPU?\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Is Running on GPU?\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras import Sequential\n",
    "import pandas\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from transformers import BertTokenizerFast, TFBertForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Our Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = \"../data\"\n",
    "# DATASET_FILE_NAME = \"hate-speech-labeled.csv\"\n",
    "DATASET_FILE_NAME = \"v3_115k/merged-dataset.csv\"\n",
    "# DATASET_FILE_NAME = \"80k_dataset/final copy.csv\"\n",
    "TEST_SIZE = 0.2\n",
    "TRAIN_SIZE = 0.8\n",
    "DATA_NEED_PREPROCESSING = False\n",
    "SENTENCE_MAX_LENGTH = 768 #512\n",
    "TOKENIZER_MODEL_NAME = \"bert-base-uncased\"\n",
    "NUM_OF_LABELS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\" momma said no pussy cats inside my doghouse \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"@Addicted2Guys: -SimplyAddictedToGuys http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"@Allyhaaaaa: Lemmie eat a Oreo &amp;amp; do these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115856</th>\n",
       "      <td>11320</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Oh fuck me hard with a rusty chainsaw, another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115857</th>\n",
       "      <td>11321</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OMG SHUT UP DRASKO AND BIANCA #MKR #FINALFIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115858</th>\n",
       "      <td>11322</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STFU drasko #MKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115859</th>\n",
       "      <td>11323</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ash found her inner bogun #whistle #fingersint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115860</th>\n",
       "      <td>11324</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sorry but #JessieJ on #thevoiceau is being a r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115808 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  class                                              tweet\n",
       "0           0    2.0  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1          40    2.0    \" momma said no pussy cats inside my doghouse \"\n",
       "2          63    2.0  \"@Addicted2Guys: -SimplyAddictedToGuys http://...\n",
       "3          66    2.0  \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...\n",
       "4          67    2.0  \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...\n",
       "...       ...    ...                                                ...\n",
       "115856  11320    2.0  Oh fuck me hard with a rusty chainsaw, another...\n",
       "115857  11321    2.0      OMG SHUT UP DRASKO AND BIANCA #MKR #FINALFIVE\n",
       "115858  11322    2.0                                   STFU drasko #MKR\n",
       "115859  11323    5.0  Ash found her inner bogun #whistle #fingersint...\n",
       "115860  11324    5.0  Sorry but #JessieJ on #thevoiceau is being a r...\n",
       "\n",
       "[115808 rows x 3 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedData = pandas.read_csv(DATASETS_PATH + \"/\" + DATASET_FILE_NAME)\n",
    "#dtype={'count': np.integer, 'class': np.integer, 'tweet': str}\n",
    "loadedData[\"class\"].values.astype(int)\n",
    "\n",
    "loadedData = loadedData.replace('',np.nan)\n",
    "loadedData = loadedData.dropna()\n",
    "\n",
    "loadedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size:  115808\n",
      "Test Size:  23161.600000000002\n",
      "Train Size:  92646.40000000001\n",
      "Does the data set have any null values?  False\n",
      "Does the data set have any duplicate values?  True\n",
      "Does the data have any missing values?  False\n",
      "Number of hate speech tweets:  7664\n",
      "Number of neutral tweets:  65551\n",
      "Number of offensive tweets:  24951\n",
      "Number of spam tweets:  10163\n",
      "Number of sexism tweets:  3009\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Size: \", len(loadedData))\n",
    "print(\"Test Size: \", len(loadedData) * TEST_SIZE)\n",
    "print(\"Train Size: \", len(loadedData) * TRAIN_SIZE)\n",
    "print(\"Does the data set have any null values? \", loadedData.isnull().values.any())\n",
    "print(\"Does the data set have any duplicate values? \", loadedData.duplicated().any())\n",
    "print(\"Does the data have any missing values? \", loadedData.isna().values.any())\n",
    "# print(\"Does the data have offensive words? \", loadedData[\"offensive_language\"].any())\n",
    "print(\"Number of hate speech tweets: \", (loadedData[\"class\"] == 0).sum())\n",
    "print(\"Number of neutral tweets: \", (loadedData[\"class\"] == 2).sum())\n",
    "print(\"Number of offensive tweets: \", (loadedData[\"class\"] == 1).sum())\n",
    "print(\"Number of spam tweets: \", (loadedData[\"class\"] == 4).sum())\n",
    "print(\"Number of sexism tweets: \", (loadedData[\"class\"] == 5).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data\n",
    "(Some data are already pre-processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing...\n",
    "data = loadedData\n",
    "\n",
    "tweetsText = data.tweet\n",
    "tweetLabels = data['class']\n",
    "tweetLabels = tweetLabels.values.astype(int)\n",
    "#[:29310]\n",
    "\n",
    "# for t in tweetLabels:\n",
    "#     t = int(t)\n",
    "#     if t != 2 and t != 0 and t != 1 and t != 3 and t != 4:\n",
    "#         print(t)\n",
    "#         print(tweetsText[list(tweetLabels).index(t)])\n",
    "\n",
    "tweetLabels = tf.keras.utils.to_categorical(tweetLabels, NUM_OF_LABELS)\n",
    "# tweetLabels = data['hate_speech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainTexts, testTexts, trainLabels, testLabels) = train_test_split(tweetsText, tweetLabels, test_size=TEST_SIZE, train_size=TRAIN_SIZE)\n",
    "\n",
    "# trainLabels\n",
    "# trainTexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting BERT Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_PREPROCESSOR_URL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "# BERT_ENCODER_URL = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "# BERT_ENCODER_URL = \"https://tfhub.dev/tensorflow/bert_en_cased_L-24_H-1024_A-16/4\"\n",
    "BERT_ENCODER_URL = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-17 02:47:47.068915: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(BERT_PREPROCESSOR_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the pro-processor model on a sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bert_preprocess_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb Cell 24'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb#ch0000023?line=0'>1</a>\u001b[0m text_test \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39mI am a bad person\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb#ch0000023?line=1'>2</a>\u001b[0m text_preprocessed \u001b[39m=\u001b[39m bert_preprocess_model(text_test)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb#ch0000023?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mKeys       : \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(text_preprocessed\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb#ch0000023?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mShape      : \u001b[39m\u001b[39m{\u001b[39;00mtext_preprocessed[\u001b[39m\"\u001b[39m\u001b[39minput_word_ids\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bert_preprocess_model' is not defined"
     ]
    }
   ],
   "source": [
    "text_test = [\"I am a bad person\"]\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Bert Model from Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = hub.KerasLayer(BERT_ENCODER_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of using Base Bert model (not fine-tuned for our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n",
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[-0.8455204  -0.31912625  0.15270585  0.66504455 -0.10829052 -0.1242601\n",
      "  0.75682086  0.12270308 -0.01685609 -0.99976     0.1998932   0.6008159 ]\n",
      "Sequence Outputs Shape:(1, 128, 768)\n",
      "Sequence Outputs Values:[[-0.05154874  0.5083577  -0.30048746 ... -0.07468746  0.32740498\n",
      "   0.2592575 ]\n",
      " [-0.06519403  0.3206128  -0.55615944 ...  0.12691334  0.92453295\n",
      "   0.31330603]\n",
      " [-0.11442744  0.24826404 -0.4793197  ... -0.23501608  0.40943736\n",
      "   0.29351258]\n",
      " ...\n",
      " [ 0.16816975  0.0566394   0.14900473 ...  0.24044822  0.2330432\n",
      "  -0.13229622]\n",
      " [-0.02244573 -0.01739264 -0.12105688 ...  0.47102982  0.24756822\n",
      "  -0.24287303]\n",
      " [-0.04622331  0.09626419 -0.11150666 ...  0.44283256  0.28327993\n",
      "  -0.10452731]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {BERT_ENCODER_URL}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classification Model based on BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  # text_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(BERT_PREPROCESSOR_URL, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(BERT_ENCODER_URL, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  # net = tf.keras.layers.Flatten()(net)\n",
    "  # net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "  net = tf.keras.layers.Dense(NUM_OF_LABELS, activation='softmax', name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierModel = build_classification_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure (Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifierModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our loss function for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "categoricalAccuracy = tf.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "recall = tf.keras.metrics.Recall(\n",
    "    thresholds=None, top_k=None, class_id=None, name=None, dtype=None\n",
    ")\n",
    "precision = tf.keras.metrics.Precision()\n",
    "\n",
    "metrics = [categoricalAccuracy, recall, precision]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTextsVariable = tf.Variable(trainTexts)\n",
    "testTextsVariable = tf.Variable(testTexts)\n",
    "\n",
    "trainDataset = tf.data.Dataset.from_tensor_slices((trainTexts, trainLabels)).batch(32)\n",
    "testDataset = tf.data.Dataset.from_tensor_slices((testTexts, testLabels)).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  5\n",
      "Steps per Epoch:  2896\n",
      "Number Train Steps:  14480\n",
      "Number Warmup Steps:  1448\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(trainDataset).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "#AdamW Optimizer is best for BERT (Initialy Adam was used with BERT)\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "\n",
    "print(\"Epochs: \", epochs)\n",
    "print(\"Steps per Epoch: \", steps_per_epoch)\n",
    "print(\"Number Train Steps: \", num_train_steps)\n",
    "print(\"Number Warmup Steps: \", num_warmup_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling our Model using the Defined Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierModel.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using {BERT_ENCODER_URL}\n",
      "Epoch 1/5\n",
      "   3/2109 [..............................] - ETA: 8:53:36 - loss: 2.1987 - accuracy: 0.1042"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/islempenywis/Source/Masters_Project/model/tf_bert.ipynb Cell 42'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project/model/tf_bert.ipynb#ch0000043?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining Model using \u001b[39m\u001b[39m{BERT_ENCODER_URL}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project/model/tf_bert.ipynb#ch0000043?line=1'>2</a>\u001b[0m trainingHistory \u001b[39m=\u001b[39m classifierModel\u001b[39m.\u001b[39;49mfit(trainDataset, validation_data\u001b[39m=\u001b[39;49mtestDataset, epochs\u001b[39m=\u001b[39;49mepochs)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py:1384\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1376'>1377</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1377'>1378</a>\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1378'>1379</a>\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1379'>1380</a>\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1380'>1381</a>\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1381'>1382</a>\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1382'>1383</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1383'>1384</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1384'>1385</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1385'>1386</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=943'>944</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=944'>945</a>\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=945'>946</a>\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=946'>947</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=947'>948</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=948'>949</a>\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=949'>950</a>\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training Model using {BERT_ENCODER_URL}\")\n",
    "trainingHistory = classifierModel.fit(trainDataset, validation_data=testDataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "classifierModel.save(\"tf_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.788936972618103,\n",
       "  0.8578733801841736,\n",
       "  0.8875615000724792,\n",
       "  0.9098535776138306,\n",
       "  0.9246309399604797],\n",
       " 'loss': [0.5554627776145935,\n",
       "  0.35772091150283813,\n",
       "  0.291880339384079,\n",
       "  0.23898841440677643,\n",
       "  0.20391052961349487],\n",
       " 'val_accuracy': [0.8498250842094421,\n",
       "  0.8491729497909546,\n",
       "  0.8529673218727112,\n",
       "  0.8644691109657288,\n",
       "  0.8685598969459534],\n",
       " 'val_loss': [0.37958553433418274,\n",
       "  0.3763718008995056,\n",
       "  0.395658940076828,\n",
       "  0.40527158975601196,\n",
       "  0.4214481711387634]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingHistory.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly test our Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/islempenywis/Source/Masters_Project/model/tf_bert.ipynb Cell 48'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project/model/tf_bert.ipynb#ch0000047?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m loadedModel\u001b[39m.\u001b[39mevaluate(testDataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testDataset' is not defined"
     ]
    }
   ],
   "source": [
    "results = classifierModel.evaluate(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss, Test accuracy [0.4214481711387634, 0.8685598969459534]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss, Test accuracy\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try sample text predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-22 00:14:31.597836: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-22 00:14:31.597876: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-05-22 00:14:54.607349: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-22 00:14:54.607437: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-22 00:14:54.607493: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ispenws-ubuntu): /proc/driver/nvidia/version does not exist\n",
      "2022-05-22 00:14:54.617543: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.0909396e-01, 3.1219041e-01, 5.7832032e-01, 3.7168062e-05,\n",
       "        3.2849706e-04, 2.9625671e-05]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# AdamWOptimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "#                                           num_train_steps=num_train_steps,\n",
    "#                                           num_warmup_steps=num_warmup_steps,\n",
    "#                                           optimizer_type='adamw')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "\n",
    "loadOptions = tf.saved_model.LoadOptions(\n",
    "    experimental_io_device='/job:localhost')\n",
    "loadedModel = tf.keras.models.load_model(\n",
    "    \"savedModels/v2\", options=loadOptions, compile=False)\n",
    "\n",
    "# preprocessedText = bert_preprocess_model([\"This is a sample tweet!\"])\n",
    "prediction = loadedModel.predict(tf.constant([\"This damn black society\"]))\n",
    "\n",
    "# print_my_examples([\"This is a sample tweet fgdfg!\"], prediction.argmax(axis=-1))\n",
    "# print(prediction.argmax(axis=-1))\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Tensorflow.js to use it in the browser\n",
    "import tensorflowjs as tfjs\n",
    "\n",
    "tfjs.converters.save_keras_model(loadedModel, './savedModels/js/v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3/724 [..............................] - ETA: 53:28 - loss: 0.2154 - accuracy: 0.9375 - recall_2: 0.9375 - precision_2: 0.9375"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb Cell 51'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb#ch0000050?line=0'>1</a>\u001b[0m \u001b[39m#Evaluate model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb#ch0000050?line=1'>2</a>\u001b[0m loadedModel\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mloss, optimizer\u001b[39m=\u001b[39moptimizer, metrics\u001b[39m=\u001b[39mmetrics)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert.ipynb#ch0000050?line=2'>3</a>\u001b[0m results \u001b[39m=\u001b[39m loadedModel\u001b[39m.\u001b[39;49mevaluate(testDataset)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1713'>1714</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1714'>1715</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1715'>1716</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1716'>1717</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1717'>1718</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=951'>952</a>\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=952'>953</a>\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=953'>954</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=954'>955</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=955'>956</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=956'>957</a>\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Evaluate model\n",
    "loadedModel.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "results = loadedModel.evaluate(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1942242681980133, 0.934368908405304, 0.9330645799636841, 0.9357274770736694]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Loss - Accuracy \n",
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8e3901b41a34b5abf67edb0498c663aeb9629d32511ecc1dcb435a30ca9b067"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
