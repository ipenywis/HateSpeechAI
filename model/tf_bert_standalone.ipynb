{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (1.4.2)\n",
      "Requirement already satisfied: sklearn in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (0.0)\n",
      "Requirement already satisfied: matplotlib in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (3.5.1)\n",
      "Requirement already satisfied: numpy in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (1.22.3)\n",
      "Requirement already satisfied: tensorflow-hub in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (0.12.0)\n",
      "Requirement already satisfied: tf-models-official in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: tensorflow-text in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (2.8.1)\n",
      "Requirement already satisfied: tensorflow in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (2.8.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from pandas) (2022.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: scikit-learn in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from sklearn) (1.0.2)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from matplotlib) (9.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from matplotlib) (3.0.8)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from matplotlib) (1.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from matplotlib) (4.32.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from matplotlib) (21.3)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow-hub) (3.20.0)\n",
      "Requirement already satisfied: tensorflow-addons in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (0.16.1)\n",
      "Requirement already satisfied: pycocotools in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (2.0.4)\n",
      "Requirement already satisfied: tensorflow-datasets in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (4.5.2)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (5.9.0)\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (1.8.0)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (2.44.0)\n",
      "Requirement already satisfied: oauth2client in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (4.1.3)\n",
      "Requirement already satisfied: Cython in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (0.29.28)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (8.0.0)\n",
      "Requirement already satisfied: opencv-python-headless in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (4.5.5.64)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (0.7.2)\n",
      "Requirement already satisfied: six in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (1.16.0)\n",
      "Requirement already satisfied: gin-config in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (0.5.0)\n",
      "Requirement already satisfied: sacrebleu in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (2.0.0)\n",
      "Requirement already satisfied: sentencepiece in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (0.1.96)\n",
      "Requirement already satisfied: pyyaml<6.0,>=5.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (5.4.1)\n",
      "Requirement already satisfied: tf-slim>=1.1.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (1.1.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (1.5.12)\n",
      "Requirement already satisfied: seqeval in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tf-models-official) (1.2.2)\n",
      "Requirement already satisfied: setuptools in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (62.1.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (13.0.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (1.44.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: gast>=0.2.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (0.24.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (4.1.1)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: tf-estimator-nightly==2.8.0.dev2021122109 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (2.8.0.dev2021122109)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (1.14.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (3.6.0)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.20.4)\n",
      "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.7.2)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (0.1.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (4.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from google-api-python-client>=1.6.7->tf-models-official) (2.6.4)\n",
      "Requirement already satisfied: certifi in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official) (2021.10.8)\n",
      "Requirement already satisfied: requests in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official) (2.27.1)\n",
      "Requirement already satisfied: tqdm in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official) (4.64.0)\n",
      "Requirement already satisfied: python-slugify in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official) (6.1.1)\n",
      "Requirement already satisfied: urllib3 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from kaggle>=1.3.9->tf-models-official) (1.26.9)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official) (0.1.7)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from oauth2client->tf-models-official) (0.4.8)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from oauth2client->tf-models-official) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from oauth2client->tf-models-official) (0.2.8)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from sacrebleu->tf-models-official) (0.8.9)\n",
      "Requirement already satisfied: portalocker in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from sacrebleu->tf-models-official) (2.4.0)\n",
      "Requirement already satisfied: colorama in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from sacrebleu->tf-models-official) (0.4.4)\n",
      "Requirement already satisfied: regex in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from sacrebleu->tf-models-official) (2022.3.15)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from scikit-learn->sklearn) (3.1.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow-addons->tf-models-official) (2.13.3)\n",
      "Requirement already satisfied: promise in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official) (2.3)\n",
      "Requirement already satisfied: tensorflow-metadata in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official) (1.7.0)\n",
      "Requirement already satisfied: dill in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from tensorflow-datasets->tf-models-official) (0.3.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.52.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client>=1.6.7->tf-models-official) (1.56.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official) (5.0.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from requests->kaggle>=1.3.9->tf-models-official) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from requests->kaggle>=1.3.9->tf-models-official) (2.0.12)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from python-slugify->kaggle>=1.3.9->tf-models-official) (1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n",
      "\u001b[33mWARNING: You are using pip version 21.3.1; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the '/home/islempenywis/Source/Masters_Project/.env/bin/python -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Install dependencies\n",
    "!pip install pandas sklearn matplotlib numpy tensorflow-hub tf-models-official tensorflow-text\n",
    "!pip install pandas sklearn matplotlib numpy tensorflow-hub tf-models-official tensorflow-text tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GITHUB REPO TOKEN\n",
    "# https://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@github.com/ipenywis/HateSpeechAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ## Grab the dataset from Github using the TEMPORARY Access Token -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git clone https://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@github.com/ipenywis/HateSpeechAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 18:28:12.892633: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/rocm/hip/lib\n",
      "2022-05-05 18:28:12.892711: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is Running on GPU?\n",
      "Num GPUs Available:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 18:28:37.706282: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: :/opt/rocm/hip/lib\n",
      "2022-05-05 18:28:37.706379: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-05 18:28:37.706474: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (ispenws-ubuntu): /proc/driver/nvidia/version does not exist\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(\"Is Running on GPU?\")\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# from keras import Sequential\n",
    "import pandas\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from transformers import BertTokenizerFast, TFBertForSequenceClassification, TrainingArguments, Trainer\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optimizer\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Our Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASETS_PATH = \"../data\"\n",
    "# DATASET_FILE_NAME = \"hate-speech-labeled.csv\"\n",
    "DATASET_FILE_NAME = \"v3_115k/merged-dataset.csv\"\n",
    "# DATASET_FILE_NAME = \"80k_dataset/final copy.csv\"\n",
    "TEST_SIZE = 0.2\n",
    "TRAIN_SIZE = 0.8\n",
    "DATA_NEED_PREPROCESSING = False\n",
    "SENTENCE_MAX_LENGTH = 768 #512\n",
    "TOKENIZER_MODEL_NAME = \"bert-base-uncased\"\n",
    "NUM_OF_LABELS = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\" momma said no pussy cats inside my doghouse \"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"@Addicted2Guys: -SimplyAddictedToGuys http://...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>66</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>2.0</td>\n",
       "      <td>\"@Allyhaaaaa: Lemmie eat a Oreo &amp;amp; do these...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115856</th>\n",
       "      <td>11320</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Oh fuck me hard with a rusty chainsaw, another...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115857</th>\n",
       "      <td>11321</td>\n",
       "      <td>2.0</td>\n",
       "      <td>OMG SHUT UP DRASKO AND BIANCA #MKR #FINALFIVE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115858</th>\n",
       "      <td>11322</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STFU drasko #MKR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115859</th>\n",
       "      <td>11323</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Ash found her inner bogun #whistle #fingersint...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115860</th>\n",
       "      <td>11324</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Sorry but #JessieJ on #thevoiceau is being a r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115808 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        count  class                                              tweet\n",
       "0           0    2.0  !!! RT @mayasolovely: As a woman you shouldn't...\n",
       "1          40    2.0    \" momma said no pussy cats inside my doghouse \"\n",
       "2          63    2.0  \"@Addicted2Guys: -SimplyAddictedToGuys http://...\n",
       "3          66    2.0  \"@AllAboutManFeet: http://t.co/3gzUpfuMev\" woo...\n",
       "4          67    2.0  \"@Allyhaaaaa: Lemmie eat a Oreo &amp; do these...\n",
       "...       ...    ...                                                ...\n",
       "115856  11320    2.0  Oh fuck me hard with a rusty chainsaw, another...\n",
       "115857  11321    2.0      OMG SHUT UP DRASKO AND BIANCA #MKR #FINALFIVE\n",
       "115858  11322    2.0                                   STFU drasko #MKR\n",
       "115859  11323    5.0  Ash found her inner bogun #whistle #fingersint...\n",
       "115860  11324    5.0  Sorry but #JessieJ on #thevoiceau is being a r...\n",
       "\n",
       "[115808 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loadedData = pandas.read_csv(DATASETS_PATH + \"/\" + DATASET_FILE_NAME)\n",
    "#dtype={'count': np.integer, 'class': np.integer, 'tweet': str}\n",
    "loadedData[\"class\"].values.astype(int)\n",
    "\n",
    "loadedData = loadedData.replace('',np.nan)\n",
    "loadedData = loadedData.dropna()\n",
    "\n",
    "loadedData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Size:  115808\n",
      "Test Size:  23161.600000000002\n",
      "Train Size:  92646.40000000001\n",
      "Does the data set have any null values?  False\n",
      "Does the data set have any duplicate values?  True\n",
      "Does the data have any missing values?  False\n",
      "Number of hate speech tweets:  7664\n",
      "Number of neutral tweets:  65551\n",
      "Number of offensive tweets:  24951\n",
      "Number of spam tweets:  10163\n",
      "Number of sexism tweets:  3009\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Size: \", len(loadedData))\n",
    "print(\"Test Size: \", len(loadedData) * TEST_SIZE)\n",
    "print(\"Train Size: \", len(loadedData) * TRAIN_SIZE)\n",
    "print(\"Does the data set have any null values? \", loadedData.isnull().values.any())\n",
    "print(\"Does the data set have any duplicate values? \", loadedData.duplicated().any())\n",
    "print(\"Does the data have any missing values? \", loadedData.isna().values.any())\n",
    "# print(\"Does the data have offensive words? \", loadedData[\"offensive_language\"].any())\n",
    "print(\"Number of hate speech tweets: \", (loadedData[\"class\"] == 0).sum())\n",
    "print(\"Number of neutral tweets: \", (loadedData[\"class\"] == 2).sum())\n",
    "print(\"Number of offensive tweets: \", (loadedData[\"class\"] == 1).sum())\n",
    "print(\"Number of spam tweets: \", (loadedData[\"class\"] == 4).sum())\n",
    "print(\"Number of sexism tweets: \", (loadedData[\"class\"] == 5).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Data\n",
    "(Some data are already pre-processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Preprocessing...\n",
    "data = loadedData\n",
    "\n",
    "tweetsText = data.tweet\n",
    "tweetLabels = data['class']\n",
    "tweetLabels = tweetLabels.values.astype(int)\n",
    "#[:29310]\n",
    "\n",
    "# for t in tweetLabels:\n",
    "#     t = int(t)\n",
    "#     if t != 2 and t != 0 and t != 1 and t != 3 and t != 4:\n",
    "        # print(t)\n",
    "        # print(tweetsText[list(tweetLabels).index(t)])\n",
    "\n",
    "tweetLabels = tf.keras.utils.to_categorical(tweetLabels, NUM_OF_LABELS)\n",
    "# tweetLabels\n",
    "# tweetLabels = data['hate_speech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainTexts, testTexts, trainLabels, testLabels) = train_test_split(tweetsText, tweetLabels, test_size=TEST_SIZE, train_size=TRAIN_SIZE)\n",
    "\n",
    "# trainTexts = [str(text) for text in trainTexts]\n",
    "# testTexts = [str(text) for text in testTexts]\n",
    "# trainLabels\n",
    "# trainTexts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting BERT Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT_PREPROCESSOR_URL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "# BERT_ENCODER_URL = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "# BERT_ENCODER_URL = \"https://tfhub.dev/tensorflow/bert_en_cased_L-24_H-1024_A-16/4\"\n",
    "BERT_ENCODER_URL = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 18:28:48.967148: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "bert_preprocess_model = hub.KerasLayer(BERT_PREPROCESSOR_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying the pro-processor model on a sample text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys       : ['input_mask', 'input_type_ids', 'input_word_ids']\n",
      "Shape      : (1, 128)\n",
      "Word Ids   : [ 101 1045 2572 1037 2919 2711  102    0    0    0    0    0]\n",
      "Input Mask : [1 1 1 1 1 1 1 0 0 0 0 0]\n",
      "Type Ids   : [0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "text_test = [\"I am a bad person\"]\n",
    "text_preprocessed = bert_preprocess_model(text_test)\n",
    "\n",
    "print(f'Keys       : {list(text_preprocessed.keys())}')\n",
    "print(f'Shape      : {text_preprocessed[\"input_word_ids\"].shape}')\n",
    "print(f'Word Ids   : {text_preprocessed[\"input_word_ids\"][0, :12]}')\n",
    "print(f'Input Mask : {text_preprocessed[\"input_mask\"][0, :12]}')\n",
    "print(f'Type Ids   : {text_preprocessed[\"input_type_ids\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Bert Model from Tensorflow Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-05 18:34:35.076895: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 93763584 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "bert_model = hub.KerasLayer(BERT_ENCODER_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of using Base Bert model (not fine-tuned for our case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded BERT: https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\n",
      "Pooled Outputs Shape:(1, 768)\n",
      "Pooled Outputs Values:[-0.8455204  -0.31912625  0.15270585  0.66504455 -0.10829052 -0.1242601\n",
      "  0.75682086  0.12270308 -0.01685609 -0.99976     0.1998932   0.6008159 ]\n",
      "Sequence Outputs Shape:(1, 128, 768)\n",
      "Sequence Outputs Values:[[-0.05154874  0.5083577  -0.30048746 ... -0.07468746  0.32740498\n",
      "   0.2592575 ]\n",
      " [-0.06519403  0.3206128  -0.55615944 ...  0.12691334  0.92453295\n",
      "   0.31330603]\n",
      " [-0.11442744  0.24826404 -0.4793197  ... -0.23501608  0.40943736\n",
      "   0.29351258]\n",
      " ...\n",
      " [ 0.16816975  0.0566394   0.14900473 ...  0.24044822  0.2330432\n",
      "  -0.13229622]\n",
      " [-0.02244573 -0.01739264 -0.12105688 ...  0.47102982  0.24756822\n",
      "  -0.24287303]\n",
      " [-0.04622331  0.09626419 -0.11150666 ...  0.44283256  0.28327993\n",
      "  -0.10452731]]\n"
     ]
    }
   ],
   "source": [
    "bert_results = bert_model(text_preprocessed)\n",
    "\n",
    "print(f'Loaded BERT: {BERT_ENCODER_URL}')\n",
    "print(f'Pooled Outputs Shape:{bert_results[\"pooled_output\"].shape}')\n",
    "print(f'Pooled Outputs Values:{bert_results[\"pooled_output\"][0, :12]}')\n",
    "print(f'Sequence Outputs Shape:{bert_results[\"sequence_output\"].shape}')\n",
    "print(f'Sequence Outputs Values:{bert_results[\"sequence_output\"][0, :12]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Classification Model based on BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classification_model():\n",
    "  text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "  # text_input = tf.keras.layers.Input(shape=(1,), dtype=tf.string, name='text')\n",
    "  preprocessing_layer = hub.KerasLayer(BERT_PREPROCESSOR_URL, name='preprocessing')\n",
    "  encoder_inputs = preprocessing_layer(text_input)\n",
    "  encoder = hub.KerasLayer(BERT_ENCODER_URL, trainable=True, name='BERT_encoder')\n",
    "  outputs = encoder(encoder_inputs)\n",
    "  net = outputs['pooled_output']\n",
    "  net = tf.keras.layers.Dropout(0.1)(net)\n",
    "  # net = tf.keras.layers.Flatten()(net)\n",
    "  # net = tf.keras.layers.Dense(1, activation=None, name='classifier')(net)\n",
    "  net = tf.keras.layers.Dense(NUM_OF_LABELS, activation='softmax', name='classifier')(net)\n",
    "  return tf.keras.Model(text_input, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierModel = build_classification_model()\n",
    "# raw_result = classifierModel(tf.constant(\"I am a bad person\"))\n",
    "# print(tf.sigmoid(raw_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure (Layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model/model_to_dot to work.\n"
     ]
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(classifierModel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our loss function for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "# metrics = tf.metrics.BinaryAccuracy()\n",
    "\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "categoricalAccuracy = tf.metrics.CategoricalAccuracy(name=\"accuracy\")\n",
    "recall = tf.keras.metrics.Recall(\n",
    "    thresholds=None, top_k=None, class_id=None, name=None, dtype=None\n",
    ")\n",
    "precision = tf.keras.metrics.Precision()\n",
    "\n",
    "metrics = [categoricalAccuracy, recall, precision]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining our optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainTextsVariable = tf.Variable(trainTexts)\n",
    "testTextsVariable = tf.Variable(testTexts)\n",
    "\n",
    "trainDataset = tf.data.Dataset.from_tensor_slices((trainTexts, trainLabels)).batch(32)\n",
    "testDataset = tf.data.Dataset.from_tensor_slices((testTexts, testLabels)).batch(32)\n",
    "\n",
    "# list(trainDataset.as_numpy_iterator())\n",
    "\n",
    "# for text_batch in trainDataset.take(100):\n",
    "  # for i in range(2):\n",
    "  # print(f'Review: ', text_batch)\n",
    "  # label = label_batch.numpy()\n",
    "  # print(f'Label : {label} ({trainLabels[label]})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epochs:  5\n",
      "Steps per Epoch:  2896\n",
      "Number Train Steps:  14480\n",
      "Number Warmup Steps:  1448\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "steps_per_epoch = tf.data.experimental.cardinality(trainDataset).numpy()\n",
    "num_train_steps = steps_per_epoch * epochs\n",
    "num_warmup_steps = int(0.1*num_train_steps)\n",
    "\n",
    "init_lr = 3e-5\n",
    "#AdamW Optimizer is best for BERT (Initialy Adam was used with BERT)\n",
    "optimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "                                          num_train_steps=num_train_steps,\n",
    "                                          num_warmup_steps=num_warmup_steps,\n",
    "                                          optimizer_type='adamw')\n",
    "\n",
    "print(\"Epochs: \", epochs)\n",
    "print(\"Steps per Epoch: \", steps_per_epoch)\n",
    "print(\"Number Train Steps: \", num_train_steps)\n",
    "print(\"Number Warmup Steps: \", num_warmup_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compiling our Model using the Defined Loss and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierModel.compile(loss=loss, optimizer=optimizer, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model using {BERT_ENCODER_URL}\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 6) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/islempenywis/Source/Masters_Project_v2/model/tf_bert_standalone.ipynb Cell 40'\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert_standalone.ipynb#ch0000039?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTraining Model using \u001b[39m\u001b[39m{BERT_ENCODER_URL}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert_standalone.ipynb#ch0000039?line=1'>2</a>\u001b[0m trainingHistory \u001b[39m=\u001b[39m classifierModel\u001b[39m.\u001b[39;49mfit(trainDataset, validation_data\u001b[39m=\u001b[39;49mtestDataset, epochs\u001b[39m=\u001b[39;49mepochs)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py:1147\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func.<locals>.autograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1144'>1145</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1145'>1146</a>\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m\"\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1146'>1147</a>\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mag_error_metadata\u001b[39m.\u001b[39mto_exception(e)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1147'>1148</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py?line=1148'>1149</a>\u001b[0m     \u001b[39mraise\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 860, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py\", line 918, in compute_loss\n        return self.compiled_loss(\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/compile_utils.py\", line 201, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/losses.py\", line 141, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/losses.py\", line 245, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/losses.py\", line 1789, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/backend.py\", line 5083, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None, 1) and (None, 6) are incompatible\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Model using {BERT_ENCODER_URL}\")\n",
    "trainingHistory = classifierModel.fit(trainDataset, validation_data=testDataset, epochs=epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 124). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "classifierModel.save(\"tf_bert_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': [0.788936972618103,\n",
       "  0.8578733801841736,\n",
       "  0.8875615000724792,\n",
       "  0.9098535776138306,\n",
       "  0.9246309399604797],\n",
       " 'loss': [0.5554627776145935,\n",
       "  0.35772091150283813,\n",
       "  0.291880339384079,\n",
       "  0.23898841440677643,\n",
       "  0.20391052961349487],\n",
       " 'val_accuracy': [0.8498250842094421,\n",
       "  0.8491729497909546,\n",
       "  0.8529673218727112,\n",
       "  0.8644691109657288,\n",
       "  0.8685598969459534],\n",
       " 'val_loss': [0.37958553433418274,\n",
       "  0.3763718008995056,\n",
       "  0.395658940076828,\n",
       "  0.40527158975601196,\n",
       "  0.4214481711387634]}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingHistory.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quickly test our Model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'testDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/islempenywis/Source/Masters_Project/model/tf_bert.ipynb Cell 48'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project/model/tf_bert.ipynb#ch0000047?line=0'>1</a>\u001b[0m results \u001b[39m=\u001b[39m loadedModel\u001b[39m.\u001b[39mevaluate(testDataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'testDataset' is not defined"
     ]
    }
   ],
   "source": [
    "results = classifierModel.evaluate(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss, Test accuracy [0.4214481711387634, 0.8685598969459534]\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Loss, Test accuracy\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try sample text predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_my_examples(inputs, results):\n",
    "  result_for_printing = \\\n",
    "    [f'input: {inputs[i]:<30} : score: {results[i][0]:.6f}'\n",
    "                         for i in range(len(inputs))]\n",
    "  print(*result_for_printing, sep='\\n')\n",
    "  print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# AdamWOptimizer = optimization.create_optimizer(init_lr=init_lr,\n",
    "#                                           num_train_steps=num_train_steps,\n",
    "#                                           num_warmup_steps=num_warmup_steps,\n",
    "#                                           optimizer_type='adamw')\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_text\n",
    "\n",
    "loadOptions = tf.saved_model.LoadOptions(\n",
    "    experimental_io_device='/job:localhost')\n",
    "loadedModel = tf.keras.models.load_model(\n",
    "    \"savedModels/v2\", options=loadOptions, compile=False)\n",
    "\n",
    "# preprocessedText = bert_preprocess_model([\"This is a sample tweet!\"])\n",
    "prediction = loadedModel.predict(tf.constant([\"This damn black society\"]))\n",
    "\n",
    "# print_my_examples([\"This is a sample tweet fgdfg!\"], prediction.argmax(axis=-1))\n",
    "print(prediction.argmax(axis=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 13/724 [..............................] - ETA: 1:02:20 - loss: 0.1785 - accuracy: 0.9423 - recall_2: 0.9423 - precision_2: 0.9423"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/islempenywis/Source/Masters_Project_v2/model/tf_bert_standalone.ipynb Cell 49'\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert_standalone.ipynb#ch0000048?line=0'>1</a>\u001b[0m \u001b[39m#Evaluate model\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert_standalone.ipynb#ch0000048?line=1'>2</a>\u001b[0m loadedModel\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39mloss, optimizer\u001b[39m=\u001b[39moptimizer, metrics\u001b[39m=\u001b[39mmetrics)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/islempenywis/Source/Masters_Project_v2/model/tf_bert_standalone.ipynb#ch0000048?line=2'>3</a>\u001b[0m results \u001b[39m=\u001b[39m loadedModel\u001b[39m.\u001b[39;49mevaluate(testDataset)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=61'>62</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=62'>63</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=63'>64</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py:1716\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1713'>1714</a>\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1714'>1715</a>\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1715'>1716</a>\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1716'>1717</a>\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/keras/engine/training.py?line=1717'>1718</a>\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=147'>148</a>\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=148'>149</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=149'>150</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=150'>151</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py?line=151'>152</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=911'>912</a>\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=913'>914</a>\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=914'>915</a>\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=916'>917</a>\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=917'>918</a>\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=950'>951</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=951'>952</a>\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=952'>953</a>\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=953'>954</a>\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=954'>955</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=955'>956</a>\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py?line=956'>957</a>\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2956\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2952'>2953</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2953'>2954</a>\u001b[0m   (graph_function,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2954'>2955</a>\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2955'>2956</a>\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=2956'>2957</a>\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1853\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1848'>1849</a>\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1849'>1850</a>\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1850'>1851</a>\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1851'>1852</a>\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1852'>1853</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1853'>1854</a>\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1854'>1855</a>\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1855'>1856</a>\u001b[0m     args,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1856'>1857</a>\u001b[0m     possible_gradient_type,\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1857'>1858</a>\u001b[0m     executing_eagerly)\n\u001b[1;32m   <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=1858'>1859</a>\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=496'>497</a>\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=497'>498</a>\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=498'>499</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=499'>500</a>\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=500'>501</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=501'>502</a>\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=502'>503</a>\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=503'>504</a>\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=504'>505</a>\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=505'>506</a>\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=506'>507</a>\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=507'>508</a>\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=510'>511</a>\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/function.py?line=511'>512</a>\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=51'>52</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=52'>53</a>\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=53'>54</a>\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=54'>55</a>\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=55'>56</a>\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/islempenywis/Source/Masters_Project/.env/lib/python3.9/site-packages/tensorflow/python/eager/execute.py?line=56'>57</a>\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Evaluate model\n",
    "loadedModel.compile(loss=loss, optimizer=optimizer, metrics=metrics)\n",
    "results = loadedModel.evaluate(testDataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "prediction = loadedModel.predict(tf.constant([\"Lets kill all jews and kill them for fun\"]))\n",
    "print(prediction.argmax(axis=-1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.1942242681980133, 0.934368908405304, 0.9330645799636841, 0.9357274770736694]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Model Loss - Accuracy \n",
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b8e3901b41a34b5abf67edb0498c663aeb9629d32511ecc1dcb435a30ca9b067"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
